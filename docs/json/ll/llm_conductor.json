{"gems":{"name":"llm_conductor","downloads":1830,"version":"1.4.0","version_created_at":"2025-11-13T18:47:09.934Z","version_downloads":11,"platform":"ruby","authors":"Ben Zheng","info":"LLM Conductor provides a clean, unified interface for working with multiple Language Model providers including OpenAI GPT, Anthropic Claude, Google Gemini, Groq, OpenRouter, and Ollama. Features include prompt templating, token counting, and extensible client architecture.","licenses":["MIT"],"metadata":{"homepage_uri":"https://github.com/ekohe/llm_conductor","changelog_uri":"https://github.com/ekohe/llm_conductor/blob/main/CHANGELOG.md","source_code_uri":"https://github.com/ekohe/llm_conductor","allowed_push_host":"https://rubygems.org","rubygems_mfa_required":"true"},"yanked":false,"sha":"9b45a331e9c92f6b1b2b6f6e1cbfdfa5a485cc9f43cee84cfa965ab9a3a2756d","spec_sha":"3d4cfb541562dce69afc84fc1c03cddd9adde11c46eda771582f0eaef44bc02c","project_uri":"https://rubygems.org/gems/llm_conductor","gem_uri":"https://rubygems.org/gems/llm_conductor-1.4.0.gem","homepage_uri":"https://github.com/ekohe/llm_conductor","wiki_uri":null,"documentation_uri":null,"mailing_list_uri":null,"source_code_uri":"https://github.com/ekohe/llm_conductor","bug_tracker_uri":null,"changelog_uri":"https://github.com/ekohe/llm_conductor/blob/main/CHANGELOG.md","funding_uri":null,"dependencies":{"development":[{"name":"rubocop-performance","requirements":"~> 1.19"},{"name":"rubocop-rspec","requirements":"~> 3.0"}],"runtime":[{"name":"activesupport","requirements":">= 6.0"},{"name":"anthropic","requirements":"~> 1.7"},{"name":"gemini-ai","requirements":"~> 4.3"},{"name":"groq","requirements":"~> 0.3"},{"name":"ollama-ai","requirements":"~> 1.3"},{"name":"ruby-openai","requirements":"~> 7.0"},{"name":"tiktoken_ruby","requirements":"~> 0.0.7"}]}},"vcs_name":"GitHub","ci":null,"vcs_uri":"https://github.com/ekohe/llm_conductor"}