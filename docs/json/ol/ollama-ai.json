{"gems":{"name":"ollama-ai","downloads":172,"version":"1.0.1","version_created_at":"2024-01-13T12:07:27.264Z","version_downloads":24,"platform":"ruby","authors":"gbaptista","info":"A Ruby gem for interacting with Ollama's API that allows you to run open source AI LLMs (Large Language Models) locally.","licenses":["MIT"],"metadata":{"homepage_uri":"https://github.com/gbaptista/ollama-ai","source_code_uri":"https://github.com/gbaptista/ollama-ai","allowed_push_host":"https://rubygems.org","rubygems_mfa_required":"true"},"yanked":false,"sha":"c66b5088096d138f98149100b292eb54daf184d69aaa836d7e121349528ec015","project_uri":"https://rubygems.org/gems/ollama-ai","gem_uri":"https://rubygems.org/gems/ollama-ai-1.0.1.gem","homepage_uri":"https://github.com/gbaptista/ollama-ai","wiki_uri":null,"documentation_uri":null,"mailing_list_uri":null,"source_code_uri":"https://github.com/gbaptista/ollama-ai","bug_tracker_uri":null,"changelog_uri":null,"funding_uri":null,"dependencies":{"development":[],"runtime":[{"name":"faraday","requirements":"~> 2.9"}]}},"vcs_name":"GitHub","ci":null,"vcs_uri":"https://github.com/gbaptista/ollama-ai"}