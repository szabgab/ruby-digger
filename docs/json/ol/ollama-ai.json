{"gems":{"name":"ollama-ai","downloads":533,"version":"1.2.0","version_created_at":"2024-02-10T19:32:29.158Z","version_downloads":20,"platform":"ruby","authors":"gbaptista","info":"A Ruby gem for interacting with Ollama's API that allows you to run open source AI LLMs (Large Language Models) locally.","licenses":["MIT"],"metadata":{"homepage_uri":"https://github.com/gbaptista/ollama-ai","source_code_uri":"https://github.com/gbaptista/ollama-ai","allowed_push_host":"https://rubygems.org","rubygems_mfa_required":"true"},"yanked":false,"sha":"bf1a1bbecb3514247ae5e185c08670b5e2abb70478c6fe62f04e16aa83085bdb","project_uri":"https://rubygems.org/gems/ollama-ai","gem_uri":"https://rubygems.org/gems/ollama-ai-1.2.0.gem","homepage_uri":"https://github.com/gbaptista/ollama-ai","wiki_uri":null,"documentation_uri":null,"mailing_list_uri":null,"source_code_uri":"https://github.com/gbaptista/ollama-ai","bug_tracker_uri":null,"changelog_uri":null,"funding_uri":null,"dependencies":{"development":[],"runtime":[{"name":"faraday","requirements":"~> 2.9"},{"name":"faraday-typhoeus","requirements":"~> 1.1"}]}},"vcs_name":"GitHub","ci":null,"vcs_uri":"https://github.com/gbaptista/ollama-ai"}