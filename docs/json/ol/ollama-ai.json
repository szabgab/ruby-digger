{"gems":{"name":"ollama-ai","downloads":1431,"version":"1.2.1","version_created_at":"2024-04-13T14:39:45.689Z","version_downloads":10,"platform":"ruby","authors":"gbaptista","info":"A Ruby gem for interacting with Ollama's API that allows you to run open source AI LLMs (Large Language Models) locally.","licenses":["MIT"],"metadata":{"homepage_uri":"https://github.com/gbaptista/ollama-ai","source_code_uri":"https://github.com/gbaptista/ollama-ai","allowed_push_host":"https://rubygems.org","rubygems_mfa_required":"true"},"yanked":false,"sha":"226cf5ae12e75327c4f25a2ce462915a404206f73181de958b19d5175139f2fe","project_uri":"https://rubygems.org/gems/ollama-ai","gem_uri":"https://rubygems.org/gems/ollama-ai-1.2.1.gem","homepage_uri":"https://github.com/gbaptista/ollama-ai","wiki_uri":null,"documentation_uri":null,"mailing_list_uri":null,"source_code_uri":"https://github.com/gbaptista/ollama-ai","bug_tracker_uri":null,"changelog_uri":null,"funding_uri":null,"dependencies":{"development":[],"runtime":[{"name":"faraday","requirements":"~> 2.9"},{"name":"faraday-typhoeus","requirements":"~> 1.1"}]}},"vcs_name":"GitHub","ci":null,"vcs_uri":"https://github.com/gbaptista/ollama-ai"}